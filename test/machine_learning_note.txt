# 特徵工程
from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder

# 數值標準化(讓資料平均值為 0、標準差為 1。常用於需要計算距離的模型，如 SVM、KNN。)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(df[['age','income']])
# X_train_scaled = scaler.fit_transform(X_train)
# scaled_data = scaler.fit_transform(data)

# Min-Max 正規化(將資料縮放到 0 到 1 之間)
mm = MinMaxScaler()
X_mm = mm.fit_transform(df[['age','income']])

# 類別編碼
le = LabelEncoder()
df['gender_encoded'] = le.fit_transform(df['gender'])

# One-Hot Encoding
df_encoded = pd.get_dummies(df, columns=['job_type'])

# 時間序列特徵(信貸或交易資料中很常見。例如，從日期時間欄位中提取年、月、日、星期幾等新特徵。)
pd.to_datetime(df['date_column'])：將欄位轉換為日期時間格式。
df['year'] = df['date_column'].dt.year
df['month'] = df['date_column'].dt.month
df['dayofweek'] = df['date_column'].dt.dayofweek

------
# 資料切分
from sklearn.model_selection import train_test_split

X = df.drop('target', axis=1)
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

------
# 模型
# Logistic Regression (違約預測、流失預測)
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# 決策樹
from sklearn.tree import DecisionTreeClassifier
tree = DecisionTreeClassifier(max_depth=5, random_state=42)
tree.fit(X_train, y_train)

# 隨機森林
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)

# XGBoost (風控常用)
from xgboost import XGBClassifier
xgb = XGBClassifier()
xgb.fit(X_train, y_train)

# 線性回歸 (利率預測)
from sklearn.linear_model import LinearRegression
reg = LinearRegression()
reg.fit(X_train, y_train)

# 梯度提升機 (Gradient Boosting)
from sklearn.ensemble import GradientBoostingClassifier
model = xgb.XGBClassifier()

# K-近鄰演算法 (KNN)
from sklearn.neighbors import KNeighborsClassifier
model = KNeighborsClassifier()

# 支持向量機 (SVM)
from sklearn.svm import SVC
model = SVC()

# 模型訓練
model.fit(X_train, y_train) # 用訓練資料訓練模型
# 模型預測
y_pred = model.predict(X_test) # 用測試資料進行預測
y_prob = model.predict_proba(X_test) # 獲取各類別的預測機率，這在風險評估中非常重要


------
# 模型評估
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.metrics import roc_auc_score, roc_curve, mean_squared_error
from sklearn.metrics import precision_score, recall_score, f1_score

# 分類模型
# 準確度 (Accuracy)
accuracy_score(y_test, y_pred)
# 精確度 (Precision)
precision_score(y_test, y_pred)
# 召回率 (Recall)
recall_score(y_test, y_pred)
# F1-Score
f1_score(y_test, y_pred)

# 混淆矩陣
confusion_matrix(y_test, y_pred)
# 模型評估報告 (精確度、召回率、F1值、樣本數)
print(classification_report(y_test, y_pred))
# AUC-ROC(信用評分、反欺詐模型中非常常用，因為它能衡量模型在不同閾值下的表現)
roc_auc_score(y_test, model.predict_proba(X_test)[:,1])

# 迴歸模型
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)


------
視覺化 (matplotlib / seaborn)
import matplotlib.pyplot as plt
import seaborn as sns

# 直方圖
sns.histplot(df['age'], bins=20)

# 箱型圖 (檢查離群值)
sns.boxplot(x='gender', y='salary', data=df)

# 散佈圖
sns.scatterplot(x='age', y='income', hue='gender', data=df)

# 熱力圖 (相關係數)
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')

# ROC 曲線
fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])
plt.plot(fpr, tpr)
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.show()

------
交叉驗證 & 調參
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.model_selection import cross_val_score, GridSearchCV

# 交叉驗證
scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')
scores.mean()

# Grid Search
param_grid = {
    'max_depth': [3, 5, 7],
    'min_samples_split': [2, 5, 10]
}
grid = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=5)
grid.fit(X_train, y_train)
grid.best_params_
grid.best_score_

------ or
# 利用StratifiedKFold做交叉驗證，相較於KFold，StratifiedKFold會照比例每個data set中抽取資料作驗證
sk_fold = StratifiedKFold(10,shuffle=True, random_state=0)

# GridSearchCV 自動調參
param = ['gini','entropy'] # 想要調參的範圍
parameters ={'criterion':param} # 想要調參的值
gs_model = GridSearchCV(estimator=DecisionTreeClassifier(class_weight='balanced',random_state=0), 
param_grid=parameters, cv=sk_fold )
gs_model.fit(x_train,y_train)

------
# 儲存與載入模型
import joblib

joblib.dump(model, 'model.pkl') # 將模型儲存為 .pkl 檔案。
loaded_model = joblib.load('model.pkl') # 載入儲存的模型。